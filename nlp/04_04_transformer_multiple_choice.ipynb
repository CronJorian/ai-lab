{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipMamgbw6bjL"
   },
   "source": [
    "# Multiple Choice: Sequential Transfer Learning mit BERT\n",
    "\n",
    "In diesem Notebook m√∂chten wir uns mit dem Shooting-Star in NLP schlechthin besch√§ftigen: **[BERT](https://arxiv.org/abs/1810.04805)**. Die Entwicklungen mit und um BERT haben seit 2019 gro√üen Einfluss auf alle Bereiche von NLP und sorgen ma√ügeblich f√ºr den Hype der letzten Jahren. \n",
    "\n",
    "> **Hintergrund zu Transformern:** BERT basiert auf einem [Transformer-Modell](https://arxiv.org/abs/1706.03762), dass initial f√ºr Sequence-to-Sequence Tasks (maschinelles √úbersetzen) entwickelt wurde. Durch dessen Erfolg wurden Transformer adaptiert und weiterentwickelt. Seither ersetzen sie in vielen Bereichen die g√§ngigen rekurrenten Netze. \n",
    "\n",
    "In diesem Notebook wollen wir uns allerdings nicht auf Transformer fokussieren, sondern die darauf basierende Modelle nutzen, um darauf ein Multiple Choice Task zu lernen (Sequential Transfer Learning). Hierf√ºr verwenden wir die Bibliothek [transformers](https://github.com/huggingface/transformers) von Hugging Face, die sowohl f√ºr Tensorflow als auch PyTorch verf√ºgbar ist. Wie √ºber das ganze Labor hinweg, wird unser Modell auf TF bzw. Keras basieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KAjNG_J7K-w"
   },
   "source": [
    "## 0. Vorbereitung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMvKYmV48aHi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Os4ySUjpnCsD"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5ZcKMwP2gQl"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tw_s4LCDbUF"
   },
   "source": [
    "Die Trainings in diesem Notebook ben√∂tigen eine GPU/TPU Runtime k√∂nnen einige Stunden dauern. Hierf√ºr kann dieser Tipp helfen: https://medium.com/@daianan/update-24-feb-2020-178a836dfbc7. \n",
    "\n",
    "√ñffnet eure Entwicklertools im Browser und f√ºhrt folgendes Skript aus, damit sich die Runtime nicht nach 30min disconnected:\n",
    "\n",
    "```javascript\n",
    "setInterval(_ => {\n",
    "  console.log(\"Working\");\n",
    "  document.querySelector(\"colab-connect-button\").shadowRoot.getElementById(\"connect\").click()\n",
    "}, 60000)\n",
    "```\n",
    "\n",
    "Denkt jedoch daran, das Browser-Fenster dann zu schlie√üen, damit die Runtime nicht f√ºr immer l√§uft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTIzE-Nj5yvf"
   },
   "source": [
    "## 1. Warm-Up mit BERT und RoBERTa\n",
    "\n",
    "Vor der eigentlichen Implementierung der Aufgabe dieses Notebooks, m√∂chten wir uns zun√§chst anschauen, wie die Modelle aufgebaut und Hugginface integriert sind.\n",
    "\n",
    "Hugging Face Transformers bietet eine Reihe an eigenen sowie Community-Modellen mit vortrainierten Gewichten. Mehr dar√ºber findet ihr in der [Modellreferenzseite](https://huggingface.co/transformers/pretrained_models.html). Ebenfalls bietet Huggingface eine gute [Dokumentation](https://huggingface.co/transformers/), die euch bei den folgenden Aufgaben helfen wird.\n",
    "\n",
    "In den Warm-Up Aufgaben m√∂chten wir uns neben [BERT](https://arxiv.org/abs/1810.04805) mit [ROBERTa](https://arxiv.org/abs/1907.11692) auch ein weiteres Modell anschauen.\n",
    "\n",
    "___\n",
    "\n",
    "Jedes in Huggingface integerierte Modell ist √ºber eine ID identifizierbar. Wir m√∂chten die folgenden beiden IDs verwenden:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvaTKtt0-XNL"
   },
   "outputs": [],
   "source": [
    "BERT_ID = 'bert-base-cased'\n",
    "ROBERTA_ID = 'roberta-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zXIt_LK9TWt"
   },
   "source": [
    "### 1.1 Tokenisierung\n",
    "\n",
    "In den bisherigen Modellen haben wir oftmals eine einfachen Word-Tokenisierung (= jedes Wort entspricht einem Token) vorgenommen. Dieses einfache Verfahren reicht bei gro√üen BERT-Modellen nicht mehr aus.\n",
    "\n",
    "Auch wenn BERT and RoBERTa eine relative √§hnliche Architektur haben, unterscheiden sie sich in Tokenisierung. Schauen wir uns mal genauer an, was dies konkret bedeutet.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "Instantiiert die spezifischen Tokenizer f√ºr BERT und ROBERTa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNF0BZHK68Ld"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = # TODO\n",
    "roberta_tokenizer = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAUrXWE9r3To"
   },
   "source": [
    "Tokenisiert den folgenden Satz f√ºr BERT und RoBERTa: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmSyr9U-YHOj"
   },
   "outputs": [],
   "source": [
    "sequence = \"The AI Lab is cool but the notebooks are too easy üòÇ.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAEOQh54ryvF"
   },
   "outputs": [],
   "source": [
    "bert_tokenized_sequence = # TODO\n",
    "roberta_tokenized_sequence = # TODO\n",
    "\n",
    "print(\"BERT:\", bert_tokenized_sequence)\n",
    "print(\"RoBERTa:\", roberta_tokenized_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emtzipi1rzjv"
   },
   "source": [
    "Beantwortet die folgenden Fragen:\n",
    "* Mit welchem Verfahren tokenisiert BERT? Wie RoBERTa?\n",
    "* Wof√ºr steht das `[UNK]` Token bei BERT?\n",
    "* Warum gibt es bei RoBERTa `ƒ†` und andere kryptische Zeichen?\n",
    "* Warum kann RoBERTa Emojis encoden, BERT aber nicht?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMip2J9Iuqoq"
   },
   "source": [
    "### 1.2. Token-Encoding\n",
    "Die Tokensierung ist ein Teilprozess des Enkodierens, um Eingabesequenzen f√ºr die Modelle verarbeitbar zu machen. Deshalb bietet jeder Tokenizer von Huggingface die Funktion `encode()` an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIKZCnJIG2qf"
   },
   "source": [
    "Nutzt die `encode`-Methode, um obige `sequence` sowohl f√ºr BERT als auch f√ºr ROBERTa zu encoden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZoVPeXRG2IG"
   },
   "outputs": [],
   "source": [
    "encoded_bert_sequence = # TODO\n",
    "encoded_roberta_sequence = # TODO\n",
    "\n",
    "print(\"Encoded BERT Sequence: \", encoded_bert_sequence)\n",
    "print(\"Encoded RoBERTa Sequence: \", encoded_roberta_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Z_-_nSFYnq2"
   },
   "source": [
    "Auf den ersten Blick sieht die enkodierte Sequenz so aus, als w√ºrde jeder Token einem Index im Vokabular zugeordnet. Dies ist prinzipiell auch richtig, jedoch f√ºgen die Modelle noch _Spezialtokens_ hinzu. \n",
    "\n",
    "  Hierf√ºr hat jeder Hugginface Tokenizer zwei Attribute `sep_token_id` und `cls_token_id`. F√ºhrt nachfolgende Zellen aus:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1cNIFOXbRWp"
   },
   "outputs": [],
   "source": [
    "bert_special_tokens = [bert_tokenizer.sep_token_id, bert_tokenizer.cls_token_id]\n",
    "roberta_special_tokens = [roberta_tokenizer.sep_token_id, roberta_tokenizer.cls_token_id] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDII8lTbYui3"
   },
   "outputs": [],
   "source": [
    "def print_in_red(string, end=' '):\n",
    "    print(f\"\\033[91m{str(string)}\\033[0m\", end=end)\n",
    "\n",
    "print(\"\\nBERT tokenized sequence\")\n",
    "[print_in_red(tok) if tok in bert_special_tokens else print(tok, end=' ') for tok in encoded_bert_sequence]\n",
    "\n",
    "print(\"\\n\\nRoBERTa tokenized sequence\")\n",
    "output = [print_in_red(tok) if tok in roberta_special_tokens else print(tok, end=' ') for tok in encoded_roberta_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZmAniY9erWf"
   },
   "source": [
    "Welche Bedeutung haben die rot markierten Tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cfNc0YyT6fj"
   },
   "source": [
    "### 1.3 Encoding mehrerer S√§tze\n",
    "\n",
    "Im n√§chsten Schritt nehmen  wir an, dass wir die folgenden beiden S√§tze f√ºr ein fiktives Modell encoden m√∂chten, dass f√ºr uns klassifiziert, ob der erste Satz den zweiten Satz paraphrasiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-Zij7nGci7Y"
   },
   "outputs": [],
   "source": [
    "sequence_1 = \"Her impoliteness, gossiping, and general lack of respect at dinner infuriated me.\"\n",
    "sequence_2 = \"She made me angry when she was rude at dinner.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7AenCtTcp4n"
   },
   "source": [
    "Enkodiert beide S√§tze. Achtet darauf, dass das BERT bzw. RoBERTA Modell die Relation zwischen den beiden S√§tzen lernen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7givE-EoJl8V"
   },
   "outputs": [],
   "source": [
    "encoded_bert_sequence = # TODO\n",
    "encoded_roberta_sequence = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oabZgOMXdjlj"
   },
   "outputs": [],
   "source": [
    "print(\"\\nBERT tokenized sequence\")\n",
    "output = [print_in_red(tok) if tok in bert_special_tokens else print(tok, end=' ') for tok in encoded_bert_sequence]\n",
    "\n",
    "print(\"\\n\\nRoBERTa tokenized sequence\")\n",
    "output = [print_in_red(tok) if tok in roberta_special_tokens else print(tok, end=' ') for tok in encoded_roberta_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WB2qhs8adl5P"
   },
   "source": [
    "Welche/s zus√§tzliche Spezialtoken wurde hinzugef√ºgt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_apacxCvZZ7"
   },
   "source": [
    "### 1.3. Encoding mit Metadaten\n",
    "\n",
    "Neben `encode()` besitzt jeder Huggingface Tokenizer eine weitere Methode `encode_plus()`, um weitere Metadaten zu erheben. Diese Methode werden wir im weiteren Verlauf auch f√ºr unser Modell verwenden. \n",
    "\n",
    "Neben den `input_ids` (die Token aus `encode()`) erhebt `encode_plus()` weitere Informationen wie die `attention_mask` und `token_type_ids`. \n",
    "\n",
    "Enkodiert die vorherigen beiden S√§tze (`sequence_1` und `sequence_2`) erneut mit `encode_plus`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtWhZ4FYLMjF"
   },
   "outputs": [],
   "source": [
    "encoded_bert_sequence = # TODO\n",
    "encoded_roberta_sequence = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwWVfZm9ez6X"
   },
   "outputs": [],
   "source": [
    "print('BERT full encoding:')\n",
    "for key in encoded_bert_sequence.keys():\n",
    "    print(f'{key}: {encoded_bert_sequence[key]}')\n",
    "\n",
    "print('\\nRoBERTa full encoding:')\n",
    "for key in encoded_roberta_sequence.keys():\n",
    "    print(f'{key}: {encoded_roberta_sequence[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-W-p-VvWexvM"
   },
   "source": [
    "Welche Bedeutung haben die `attention_mask` und `token_type_ids` f√ºr die Modelle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUCYkM9y-0Sg"
   },
   "source": [
    "## 2. Fine-Tuning von BERT f√ºr Multiple Choice\n",
    "In diesem Schritt wird das zum Tokenizer passende Sprachmodell f√ºr BERT \"verfeinert\", um es f√ºr die Beantwortung von Multiple-Choice Fragen zu verwenden. Es handelt sich also um eine spezielle Form von Transfer Learning (**Sequential Transfer Learning**), bei der ein vortrainiertes Modell auf einen speziellen Downstream Task (in unserem Fall Multiple Choice) angepasst wird. \n",
    "\n",
    "___\n",
    "\n",
    "Als vortrainierten Sprachmodell wird BERT verwendet und f√ºr den [SWAG Datensatz](https://rowanzellers.com/swag/) angepasst. Dieser besteht aus 113.000 Multiple Choice Fragen. Verschafft euch ein erstes Bild vom Datensatz, da es sich nicht um das klassisches Multiple Choice handelt.\n",
    "\n",
    "Im Detail, werden wir die folgenden Schritte durchf√ºhren:\n",
    "1. SWAG Daten von Github laden.\n",
    "2. Daten verarbeiten in interpretierbare Samples\n",
    "3. Samples in Features konvertieren, die f√ºr BERT Modelle verarbeitbar sind.\n",
    "4. Generator f√ºr das Keras Modell erzeugen.\n",
    "5. Modell aufbauen und Trainieren\n",
    "6. Modell evaluieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4V5mvbzWA7UL"
   },
   "source": [
    "### 2.1 Datensatz von GitHub laden\n",
    "\n",
    "Der SWAG Datensatz ist verf√ºgbar auf Github und kann wie folgt geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "f69G7vrSOZ7N",
    "outputId": "06af9216-09ff-4e4b-f7a7-7b669f3776c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './swag'...\n",
      "remote: Enumerating objects: 188, done.\u001b[K\n",
      "remote: Total 188 (delta 0), reused 0 (delta 0), pack-reused 188\u001b[K\n",
      "Receiving objects: 100% (188/188), 14.82 MiB | 6.53 MiB/s, done.\n",
      "Resolving deltas: 100% (88/88), done.\n",
      "total 82532\n",
      "drwxr-xr-x 2 root root     4096 May 14 06:17 .\n",
      "drwxr-xr-x 7 root root     4096 May 14 06:17 ..\n",
      "-rw-r--r-- 1 root root     2502 May 14 06:17 README.md\n",
      "-rw-r--r-- 1 root root  7817885 May 14 06:17 test.csv\n",
      "-rw-r--r-- 1 root root 28243333 May 14 06:17 train.csv\n",
      "-rw-r--r-- 1 root root 31608559 May 14 06:17 train_full.csv\n",
      "-rw-r--r-- 1 root root  7893588 May 14 06:17 val.csv\n",
      "-rw-r--r-- 1 root root  8929065 May 14 06:17 val_full.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './swag/data'\n",
    "! git clone https://github.com/rowanz/swagaf/ './swag'\n",
    "! ls -la {DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDmSnHkS10l1"
   },
   "source": [
    "### 2.2 Datensatz verarbeiten\n",
    "\n",
    "Im ersten Schritt lesen wir jedes Sample des Train-, Validation- und Test-Datensatzes in eine Klasse `InputExample` ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxaQOCwS2uBI"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single example for multiple choice\"\"\"\n",
    "\n",
    "    def __init__(self, example_id, question, contexts, endings, label=None):\n",
    "        self.example_id = example_id\n",
    "        self.question = question\n",
    "        self.contexts = contexts\n",
    "        self.endings = endings\n",
    "        self.label = label\n",
    "\n",
    "def create_examples(lines: List[List[str]]):\n",
    "    \"\"\"\n",
    "      Creates examples for the training and dev sets.\n",
    "    \n",
    "    \"\"\"\n",
    "    return [\n",
    "        InputExample(\n",
    "            example_id=line[2],\n",
    "            question=line[5],  # In the swag dataset, the answers have a common beginning (a \"QUESTION\").\n",
    "            contexts=[line[4], line[4], line[4], line[4]], # Each ending has the same context\n",
    "            endings=[line[7], line[8], line[9], line[10]], # 4 different endings (answers)\n",
    "            label=line[11],\n",
    "        )\n",
    "        for line in lines[1:]  # we skip the line with the column names\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CLWH27Ek2bZ"
   },
   "source": [
    "Jede Frage (`question`) besteht aus vier m√∂glichen Antworten (`endings`), die jeweils den selben Kontext haben (`contexts`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOkj2j9N4Y4H"
   },
   "source": [
    "Erzeugt eine Liste von `InputExample`-Instanzen f√ºr das Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLvofJrIOyri"
   },
   "outputs": [],
   "source": [
    "train_examples = # TODO\n",
    "print(f'{len(train_examples)} total training samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_qv4OONm3oq"
   },
   "source": [
    "Gebt euch einige Beispiel aus, um ein Gef√ºhl f√ºr die Daten zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1IjwR4SlGaK"
   },
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, len(train_examples)-1)\n",
    "print('Context:\\t', train_examples[random_idx].contexts[0])\n",
    "print('Beginning:\\t', train_examples[random_idx].question)\n",
    "for i, ending in enumerate(train_examples[random_idx].endings):\n",
    "  msg = f'Ending {i}:\\t {ending}'\n",
    "  print_in_red(msg, end='\\n') if i == int(train_examples[random_idx].label) else print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NOdlYWW4kGF"
   },
   "source": [
    "Erstellt analog einen Validation- und Test-Datensatz. \n",
    "\n",
    "> Da SWAG keinen expliziten Test-Datensatz besitzt, nutzen wir 30% des Validation Sets f√ºr den Test-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "qtgJFyGx4jS_",
    "outputId": "da457b38-653a-4f9b-f4dd-18eda1d7d161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14004 total validation samples\n",
      "6001 total test samples\n"
     ]
    }
   ],
   "source": [
    "test_examples, valid_examples = # TODO\n",
    "\n",
    "print(f'{len(valid_examples)} total validation samples')\n",
    "print(f'{len(test_examples)} total test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXxId8eG4_xq"
   },
   "source": [
    "Dar√ºber hinaus ben√∂tigen wir eine Liste aller Labels (als strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYOly5P_1zPz"
   },
   "outputs": [],
   "source": [
    "label_list = [\"0\", \"1\", \"2\", \"3\"]\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G585gwCHpM0t"
   },
   "source": [
    "Damit haben wir nun drei Datens√§tze `train_examples`, `valid_examples` und `test_examples`, die jeweils Samples der Klasse `InputExample` beinhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJOkr87TC5RX"
   },
   "source": [
    "### 2.3 Datensatz encodieren und in Feature konvertieren\n",
    "\n",
    "Im n√§chsten Schritt nutzen wir unser Wissen aus den Warmup-Aufgaben, um die `InputExample`-Liste zu enkodieren. Hierf√ºr wird jedes `InputExample` in eine korrespondierende `InputFeature`-Klasse konvertiert.\n",
    "\n",
    "> Aus Komplexit√§tsgrunden haben wir uns daf√ºr entschieden, dass ihr das SWAG Modell sp√§ter nicht selbst modellieren, sondern auf `TFBertForMultipleChoice` von HuggingFace Transformers zur√ºckgreifen k√∂nnt. Ihr m√ºsst also \"nur\" die Daten in das richtige Format bringen, das vom implementierten Modell unterst√ºtzt wird. \n",
    "\n",
    "Jetzt w√§re ein guter Zeitpunkt, sich den Quellcode des Modells [hier](https://github.com/huggingface/transformers/blob/64070cbb8875f727b96cde285052fa037545a814/src/transformers/modeling_tf_bert.py#L938) genau anzuschauen, um zu verstehen, auf welche Form ihr die Daten bringt m√ºsst.\n",
    "\n",
    "____\n",
    "\n",
    "Definiert als erstes eine sinnvolle maximale Sequenzl√§nge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qap5z3e6QjLn"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1-8LH2TLqfOl"
   },
   "outputs": [],
   "source": [
    "class InputFeature(object):\n",
    "    def __init__(self, example_id, choices_features, label):\n",
    "        self.example_id = example_id\n",
    "        # We cannot store the choices_features as it is, since the BERT model\n",
    "        # requires another  format\n",
    "        self.input_ids, self.attention_mask, self.token_type_ids = zip(*choices_features)\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XA0oAlVD1nE"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer \n",
    "import tqdm\n",
    "\n",
    "def convert_examples_to_features(\n",
    "    examples: List[InputExample],\n",
    "    label_list: List[str],\n",
    "    max_length: int,\n",
    "    tokenizer: BertTokenizer,\n",
    ") -> List[InputFeature]:\n",
    "    \"\"\"\n",
    "    Loads a set of examples into a list of `InputFeature`s\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_idx, example) in tqdm.tqdm(enumerate(examples), desc=\"Convert examples to features\"):\n",
    "        \n",
    "        choices_features = []\n",
    "        for ending_idx, (context, ending) in enumerate(zip(example.contexts, example.endings)):\n",
    "            text_a = # TODO\n",
    "            text_b = f'{example.question} {ending}'\n",
    "\n",
    "            input_ids, token_type_ids, attention_mask = # TODO\n",
    "\n",
    "            # We have to pad the above to max sequence length\n",
    "            input_ids = # TODO\n",
    "            attention_mask = # TODO\n",
    "            token_type_ids = # TODO\n",
    "\n",
    "            assert len(input_ids) == max_length\n",
    "            assert len(attention_mask) == max_length\n",
    "            assert len(token_type_ids) == max_length\n",
    "\n",
    "            choices_features.append((input_ids, attention_mask, token_type_ids))\n",
    "\n",
    "        label = label_map[example.label]\n",
    "        features.append(InputFeature(example.example_id, choices_features, label))\n",
    "\n",
    "        if ex_idx == 0:\n",
    "          print(\"*** Example ***\")\n",
    "          print(\"race_id: {}\".format(example.example_id))\n",
    "          for choice_idx, (input_ids, attention_mask, token_type_ids) in enumerate(choices_features):\n",
    "              print(\"choice: {}\".format(choice_idx))\n",
    "              print(\"input_ids: {}\".format(\" \".join(map(str, input_ids))))\n",
    "              print(\"attention_mask: {}\".format(\" \".join(map(str, attention_mask))))\n",
    "              print(\"token_type_ids: {}\".format(\" \".join(map(str, token_type_ids))))\n",
    "              print(\"label: {}\".format(label))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnUOuzHDrRRD"
   },
   "source": [
    "Konvertiert als erstes die `train_examples` und anschlie√üend die `valid_examples` in Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViM3Fk3-F3CF"
   },
   "outputs": [],
   "source": [
    "train_features = # TODO\n",
    "valid_features = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVfhuSGFPhIC"
   },
   "source": [
    "### 2.4. Datensatz-Generator  \n",
    "\n",
    "Zum Abschluss m√ºssen die Features noch in f√ºr Tensorflow verst√§ndliche Form gebracht werden. Hierf√ºr verwenden wir wieder einen DataGenerator, der die `InputFeature`s einliest und ein Datensatz generiert. Dieser Generator wird anschlie√üend an `tf.data.Dataset.from_generator` zum Tensorflow Dataset.\n",
    "\n",
    "(Sp√§testens jetzt m√ºsst ihr wissen, in welchem Eingabeformat das Modell die Daten ben√∂tigt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pmoxb7fPpUX"
   },
   "outputs": [],
   "source": [
    "def create_dataset(features: List[InputFeature]) -> tf.data.Dataset:\n",
    "\n",
    "    def gen():\n",
    "        \"\"\" The actual generator for multiple choice features\"\"\"\n",
    "        # TODO\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        (\n",
    "            {\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32},\n",
    "            tf.int64\n",
    "        ),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([num_labels, MAX_SEQ_LENGTH]),\n",
    "                \"attention_mask\": tf.TensorShape([num_labels, MAX_SEQ_LENGTH]),\n",
    "                \"token_type_ids\": tf.TensorShape([num_labels, MAX_SEQ_LENGTH]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TBDUs6XPxvI"
   },
   "outputs": [],
   "source": [
    "train_dataset = # TODO\n",
    "valid_dataset = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKqsfKzGsRb3"
   },
   "source": [
    "### 2.5 Klassifikation\n",
    "\n",
    "Voil√°, der komplizierteste Teil ist geschafft. Wir haben den Datensatz in ein Format gebracht, das das vortrainierte BERT-Modell verarbeiten kann. In diesem Schritt m√∂chten wir nun das entsprechende Modell verarbeiten.\n",
    "\n",
    "> Die Batch Size ist stark abh√§ngig von der Sequenzl√§nge (`MAX_SEQ_LENGTH`) beim Encoding. Falls ihr also Memory-Probleme bekommt, verringert entweder die maximale Sequenzl√§nge oder die Batchgr√∂√üe. Achtet aber auch darauf, die GPU/TPU immer komplett auszulasten (sonst dauert das Training sehr lange)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOL4-FJ8sCYb"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = # TODO\n",
    "EVAL_BATCH_SIZE = BATCH_SIZE*2\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mbky1nFOYA6"
   },
   "source": [
    "Teilt nun die beiden Datens√§tze `train_dataset` und `valid_dataset` auf Batches der Gr√∂√üe `batch_size` auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAWtYHwPFNQa"
   },
   "outputs": [],
   "source": [
    "train_dataset = # TODO\n",
    "valid_dataset = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmeREe68OiPh"
   },
   "source": [
    "Nun muss das `TFBertForMultipleChoice` Modell geladen werden, welches die Architektur f√ºr ein Multiple Choice Modell bietet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "LDQae04GtTet"
   },
   "outputs": [],
   "source": [
    "model = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-W0QxDuFtpat"
   },
   "source": [
    "Schaut euch das Modell an und beantworte folgende Verst√§ndnisfragen: \n",
    "\n",
    "1. Wie integriert `TFBertForMultipleChoice` das vortrainierte BERT-Modell?\n",
    "2. Wie wird die Eingabe der Shape `(batch_size, num_choices, seq_length)` so angepasst, dass BERT sie verarbeiten kann?\n",
    "3. Kann das BERT Modell Beziehungen zwischen den Antwortm√∂glichkeiten einer Frage lernen?\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d40UOXfiPS06"
   },
   "source": [
    "√úberlegt euch nun, welche `loss` und `metric` f√ºr diesen Problem Sinn machen. Als Optimizer k√∂nnt ihr `Adam` nutzen. Achtet darauf, dass eure Lernrate relativ klein ist (z.B. `3e-5`). \n",
    "\n",
    "Worin besteht Gefahr, wenn die Lernrate zu gro√ü ist? (Tipp: Schaut euch hierf√ºr die Anzahl an Parametern der einzelnen Schichten an)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QQjJcNe4STw"
   },
   "outputs": [],
   "source": [
    "loss = # TODO\n",
    "metric = # TODO\n",
    "opt = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vA52FPkWuSym"
   },
   "outputs": [],
   "source": [
    "model.compile() # TODO\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qL-BaC5RP4nc"
   },
   "source": [
    "Training: Nutzt die bekannte `model.fit()` Methode um das Modell zu trainieren und zu validieren. Vergesst nicht, dass wir hierf√ºr eine GPU ben√∂tigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yytX32quKav"
   },
   "outputs": [],
   "source": [
    "model.fit() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fh-BQy9aib4O"
   },
   "source": [
    "Wie interpretiert ihr den Trainingsverlauf? Welche Annahmen lassen sich heraus f√ºr die Verwendung von BERT f√ºr in anderen Klassifikations-Tasks treffen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69podIBTMXQq"
   },
   "source": [
    "### 2.6 Evaluation auf Test-Set\n",
    "Da wir nun ein Modell entwickelt haben, dass auf den Standard-Keras Methoden basiert, k√∂nnen wir das Modell evaluieren. \n",
    "\n",
    "Ladet hierf√ºr die oben vorbereiteten `text_examples` (30% Split der Validierungsdaten) und evaluiert den Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scT82c9arCRv"
   },
   "outputs": [],
   "source": [
    "test_dataset = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjEiF13ssV9p"
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate() # TODO\n",
    "print(f\"Accuracy on the test dataset {}\") # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9dxqi1Ry7xK"
   },
   "source": [
    "Wie gut generalisiert das Modell auf die Testdaten? Vergleicht eure Resultate mit den Ergebnisse (auf dem nicht ganz repr√§sentativen Test-Set) mit dem [Leaderboard](https://leaderboard.allenai.org/swag/submissions/public). \n",
    "\n",
    "* Wie schneidet ihr ab?\n",
    "* Verglichen mit dem BERT-Large Modell im Leaderboard, warum ist eure Performance schw√§cher?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "06_03_transformer_multiple_choice",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
