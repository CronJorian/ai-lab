{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nG90pwjB-cIO"
   },
   "source": [
    "# HSKA AI-Lab RL: Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCTFrfsv-g5V"
   },
   "source": [
    "## Mount Google Drive as folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODLMGwrk-gIJ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "%cd /content/drive/My\\ Drive/ai-lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3ghLMfm-cIf"
   },
   "source": [
    "Es soll ein DQN Agent trainiert werden, der [Atari Breakout](https://www.gymlibrary.ml/environments/atari/breakout/) spielen kann.\n",
    "Der Ansatz ist frei – ihr könnt euch an Aufgabe 4 orientieren oder die Methode auf eure Art implementieren.\n",
    "\n",
    "### \"Quiz\"\n",
    "\n",
    "- Wann ist der Agent gut genug? Was ist ein gutes Erfolgskriterium?\n",
    "- Was für eine Architektur soll das Q-Network haben?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBDgFNq5-cIf"
   },
   "source": [
    "### It's dangerous to go alone! Take this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bD9bTND8-cIp"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "%pip install --upgrade pip\n",
    "%pip install gym[atari]==0.12.5\n",
    "%pip install pyglet==1.3.2\n",
    "\n",
    "import gym\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Tuple\n",
    "import time\n",
    "from datetime import datetime\n",
    "from contextlib import suppress\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Lambda, multiply, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.losses import huber_loss\n",
    "from tensorflow.keras.backend import set_session\n",
    "from loggers import TensorBoardLogger, tf_summary_image\n",
    "\n",
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from plot_utils import plot_statistics\n",
    "from abstract_agent import AbstractAgent\n",
    "from atari_helpers import LazyFrames, wrap_deepmind, make_atari\n",
    "\n",
    "!apt-get install -y xvfb python-opengl\n",
    "!python -m pip install pyvirtualdisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "    from IPython.display import SVG\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D--k_Yo4-cIw"
   },
   "outputs": [],
   "source": [
    "# familiar interface:\n",
    "env = make_atari('BreakoutNoFrameskip-v0')\n",
    "env = wrap_deepmind(env, frame_stack=True)\n",
    "\n",
    "# or vanilla open ai gym:\n",
    "# env = gym.make('BreakoutNoFrameskip-v0')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_atari_pong_dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
