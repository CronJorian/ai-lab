{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cv_3_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# **CIFAR10**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGkt5qiyz4E"
      },
      "source": [
        "In this notebook you will explore different methods for avoiding overfitting and improving accuracy when using [Convolutional Neural Networks](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) to classify [CIFAR images](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "**Task:**\n",
        "\n",
        "- Please follow the instructions complete all the missing code.\n",
        "- Questions (marked with QUESTION tag) requires you to answer the posed question with a short and concise answer.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- Keep in mind that there are multiple ways to solve implement some part or answer some questions.\n",
        "- If you need any help use the [Tensorflow Documentation](https://www.tensorflow.org/) or the [Keras Documentation](https://keras.io)\n",
        "- Be creative! The data augmentation task gives you a lot of freedom to try out your ideas for best data augmentation techniques. But please keep in mind that you should be able to explain the reasoning behind your decisions.\n",
        "- In case of blocking problems you can ask for help during our Q&A sessions or discuss it with other students in the slack channel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "### Download and prepare the CIFAR10 dataset\n",
        "\n",
        "\n",
        "The CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. We will divide the dataset into 40,000 training images, 10,000 validation images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "source": [
        "(dataset_images, dataset_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# TODO: Split the dataset using 80% 10% 10% split.\n",
        "# That means you want to end up with 40k training, 10k validation\n",
        "# and 10k test samples\n",
        "# NOTE: If you prefer to do the train/validation split using the keras api later\n",
        "# you are free to do so\n",
        "\n",
        "dataset_size = dataset_images.shape[0]\n",
        "\n",
        "train_images =\n",
        "val_images =\n",
        "\n",
        "train_labels =\n",
        "val_labels =\n",
        "\n",
        "# TODO: Normalize pixel values to be between 0 and 1\n",
        "train_images, val_images, test_images = train_images / 255.0, val_images / 255.0, test_images / 255.0\n",
        "\n",
        "assert train_images.shape == (40000, 32, 32, 3)\n",
        "assert val_images.shape == (10000, 32, 32, 3)\n",
        "assert test_images.shape == (10000, 32, 32, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wArwCTJJlUa"
      },
      "source": [
        "### Explore the dataset\n",
        "\n",
        "To get a better intuition about the data we are using it is always good to inspect the dataset and look at some examples.\n",
        "Let's plot a couple of images for every class label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3PAELE2eSU9"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# TODO: plot two images from the dataset for each of the class names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Create the CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQvqXpNyN3x"
      },
      "source": [
        "Below you see a method to create our baseline CNN model. It is based on stacking of [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) with ReLU activations and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
        "\n",
        "Usually a CNN takes input of shape (image_height, image_width, channels), ignoring the batch size. The channels refers to color channels in the images (R,G,B). CIFAR images have the shape (32, 32, 3). To accomodate this we are passing the argument `input_shape` to the first layer.\n",
        "\n",
        "Finally to arrive at the laste dense layer with shape (num_classes), we need to flatten the output of the last pooling layer and add a couple of dense layers. CIFAR has 10 output classes, so you use a final Dense layer with 10 outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "source": [
        "# NOTE: Do not change this code!!! We use this as our baseline model to see\n",
        "# the improvement of the test accuracy after our modifications.\n",
        "\n",
        "def create_model():\n",
        "  '''Create simple 6 layer CNN model for classifying CIFAR10 images'''\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=train_images.shape[1:]))  # input_shape is (32, 32, 3)\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.Conv2D(32,(3, 3)))\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.Conv2D(64, (3,3)))\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512))\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LHEzT4Zxrvk"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Train and evaluate the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# NOTE: if you decided not to manually split the dataset to train/val then you\n",
        "# will need to adapt the following call to fit\n",
        "# NOTE: Use 20 epochs for all training trials during this exercise!\n",
        "history = model.fit(train_images, train_labels, epochs=20, \n",
        "                    validation_data=(val_images, val_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2z7-k5B0FpV"
      },
      "source": [
        "# TODO: plot the training and validation accuracy over epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdPaNPQj0MnM"
      },
      "source": [
        "# Print the test accuracy after training\n",
        "# NOTE: The test accuracy of our baseline model should be in the range 0.71-0.73\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-JwwyrcTA-u"
      },
      "source": [
        "# Extending the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H1ghID5S_31"
      },
      "source": [
        "# TODO: copy paste the baseline model from above\n",
        "# TODO: add Batch Normalization to the model\n",
        "# NOTE: where to add the Batch Normalization is an ongoing discussion\n",
        "# different researchers argue that it is better to add it before or after the\n",
        "# activation in the model. Read some of the discussions and decide for yourself:\n",
        "# - https://arxiv.org/abs/1502.03167\n",
        "# - https://www.reddit.com/r/MachineLearning/comments/2x0bq8/some_questions_regarding_batch_normalization/?su=ynbwk&st=iprg6e3w&sh=88bcbe40\n",
        "# - https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n",
        "# TODO: add Dropout to the model. Again research a bit on the internet and\n",
        "# decide for yourself where you think adding the Dropout layer is best and with\n",
        "# how much rate. Try different settings and decide what best works for you.\n",
        "\n",
        "def create_model_dropout_batchnorm():\n",
        "  model = models.Sequential()\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3TdCCMp2ULk"
      },
      "source": [
        "# Initialize and train the extended model\n",
        "ext_model = create_model_dropout_batchnorm()\n",
        "\n",
        "ext_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# TODO: add early stopping to the training\n",
        "# NOTE: You can do this the easy or the hard way\n",
        "# - the easy way just means defining the EarlyStopping callback from the keras\n",
        "# api and using it in the call to fit\n",
        "# - the hard way means writing your own training loop. If you want to learn how\n",
        "# to this there is are simple examples here:\n",
        "# - https://www.tensorflow.org/tutorials/quickstart/advanced\n",
        "# - https://stackoverflow.com/questions/46428604/how-to-implement-early-stopping-in-tensorflow\n",
        "# After having written your own training loop, you can easily implement the\n",
        "# early stopping feature by stopping the loop when the validation loss or\n",
        "# accuracy gets worse between iterations\n",
        "\n",
        "# TODO: call ext_model.fit with early stopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WckMciIoTkQs"
      },
      "source": [
        "# TODO: plot the training and validation accuracy over epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeiFKTW53c7z"
      },
      "source": [
        "# Print the test accuracy after training\n",
        "# NOTE: The test accuracy of our extended model should be above 0.805\n",
        "test_loss, test_acc = ext_model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1qpVHko3muN"
      },
      "source": [
        "#### TODO:\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "- What does the `patience` parameter in the `tf.keras.callbacks.EarlyStopping` do? Why is it necessary and how does it help?\n",
        "- What is dropout method used for? Why does it help? Why doesn't it make the test accuracy worse?\n",
        "- Where did you position the BatchNorm layers and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRcZwLUFUICF"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJpFHACD1G2K"
      },
      "source": [
        "### Augmentation functions\n",
        "\n",
        "The cell below includes two example transformations to be used for data augmentation. Use them as templates and inspiration for writing your own transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIJUlWrNUskJ"
      },
      "source": [
        "# TODO: write two more image transformation functions\n",
        "\n",
        "def flip(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Flip augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image to flip\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def color(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Color augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_hue(x, 0.01)\n",
        "    x = tf.image.random_saturation(x, 0.9, 1.1)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BnWmQkI1ULF"
      },
      "source": [
        "### Dataset augmentation, training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5SGl6NSrQGS"
      },
      "source": [
        "# First let us visualise the image transformations we defined above.\n",
        "\n",
        "def plot_images(dataset, n_images, samples_per_image):\n",
        "    output = np.zeros((32 * n_images, 32 * samples_per_image, 3))\n",
        "\n",
        "    row = 0\n",
        "    for images in dataset.repeat(samples_per_image).batch(n_images):\n",
        "        output[:, row*32:(row+1)*32] = np.vstack(images.numpy())\n",
        "        row += 1\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(output)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# We will use the Dataset api for easier mapping of image transformations to the\n",
        "# CIFAR10 dataset. Here we only use the first 8 images from the dataset to\n",
        "# visualize our transformations\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(train_images).take(8)\n",
        "\n",
        "augmentations = [flip, color]\n",
        "\n",
        "for f in augmentations:\n",
        "    # NOTE: we are aplying the transformation 75% of the time\n",
        "    dataset = dataset.map(lambda x: tf.cond(tf.random.uniform([], 0, 1) > 0.75, \n",
        "                                            lambda: f(x), \n",
        "                                            lambda: x), num_parallel_calls=4)\n",
        "\n",
        "# Transformations might make the pixel values go out of range so we clip them\n",
        "dataset = dataset.map(lambda x: tf.clip_by_value(x, 0, 1))\n",
        "\n",
        "plot_images(dataset, n_images=8, samples_per_image=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpeMxNfiWM0a"
      },
      "source": [
        "# Now we use the Dataset api on the whole training and validation set\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(32)\n",
        "\n",
        "# Add the augmentations\n",
        "for f in augmentations:\n",
        "    # NOTE: Feel free to change the probability of the augmentation\n",
        "    f_aug = lambda x, y: (tf.cond(tf.random.uniform([], 0, 1) > 0.75,\n",
        "                                  lambda: f(x),\n",
        "                                  lambda: x), y)\n",
        "    train_dataset = train_dataset.map(f_aug)\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.clip_by_value(x, 0, 1), y))\n",
        "\n",
        "# We use the baseline model here because we want to compare the test accuracy of\n",
        "# data augmentation approach with the extended model!\n",
        "aug_model = create_model()\n",
        "\n",
        "aug_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = aug_model.fit(train_dataset, epochs=20, validation_data=val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LVK6aBLX9FC"
      },
      "source": [
        "# TODO: plot the training and validation accuracy over epochs\n",
        "\n",
        "\n",
        "# Print the test accuracy after training\n",
        "# NOTE: The test accuracy of our model with data augmentation (including your\n",
        "# added augmentations) should be at least above 0.745\n",
        "test_loss, test_acc = aug_model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqu9oxVF-ohv"
      },
      "source": [
        "#### TODO:\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "- How does the data augmentation help improve the accuracy of the model?\n",
        "- What would be the optimal data augmentation for a specific task?\n",
        "- Which of the methods we used so far (dropout, batch norm, early stopping, data augmentation) improved the accuracy the most? Support you answer with data. Discuss the potential reasons why did this method improve the accuracy more than other methods?"
      ]
    }
  ]
}